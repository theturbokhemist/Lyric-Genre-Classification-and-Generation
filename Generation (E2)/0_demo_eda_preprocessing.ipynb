{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This notebooks serves as the basic exploratory data analysis and demonstrating the interfaces of the `Tokenizer` and `Embedding` modules created for the purpose of language modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80285, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Song</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Britney Spears</td>\n",
       "      <td>...Baby One More Time</td>\n",
       "      <td>Oh, baby, baby Oh, baby, baby  Oh, baby, baby...</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Britney Spears</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>Baby, can't you see I'm calling? A guy like y...</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Britney Spears</td>\n",
       "      <td>Work Bitch</td>\n",
       "      <td>You wanna? You wanna?  You want a hot body? Y...</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Britney Spears</td>\n",
       "      <td>Oops!... I Did It Again</td>\n",
       "      <td>Mmm, yeah Yeah, yeah, yeah, yeah, yeah, yeah ...</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Britney Spears</td>\n",
       "      <td>If U Seek Amy</td>\n",
       "      <td>La, la, la, la, la-la, la, la La, la, la, la,...</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Artist                     Song  \\\n",
       "0  Britney Spears    ...Baby One More Time   \n",
       "1  Britney Spears                    Toxic   \n",
       "2  Britney Spears               Work Bitch   \n",
       "3  Britney Spears  Oops!... I Did It Again   \n",
       "4  Britney Spears            If U Seek Amy   \n",
       "\n",
       "                                              Lyrics Genre  \n",
       "0   Oh, baby, baby Oh, baby, baby  Oh, baby, baby...   Pop  \n",
       "1   Baby, can't you see I'm calling? A guy like y...   Pop  \n",
       "2   You wanna? You wanna?  You want a hot body? Y...   Pop  \n",
       "3   Mmm, yeah Yeah, yeah, yeah, yeah, yeah, yeah ...   Pop  \n",
       "4   La, la, la, la, la-la, la, la La, la, la, la,...   Pop  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/df_lyrics.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rock 21962\n",
      "Rap 18331\n",
      "Pop 18275\n",
      "Country 21717\n"
     ]
    }
   ],
   "source": [
    "for genre in set(df.Genre):\n",
    "    print(genre, df[df.Genre == genre].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Oh,', 'baby,', 'baby', 'Oh,', 'baby,', 'baby', 'Oh,', 'baby,', 'baby', 'How', 'was', 'I', 'supposed', 'to', 'know', 'That', 'something', \"wasn't\", 'right', 'here?', 'Oh,', 'baby,', 'baby', 'I', \"shouldn't\", 'have', 'let', 'you', 'go', 'And', 'now', \"you're\", 'out', 'of', 'sight,', 'yeah', 'Show', 'me', 'how', 'you', 'want', 'it', 'to', 'be', 'Tell', 'me,', 'baby,', \"'cause\", 'I', 'need', 'to', 'know', 'now', 'Oh,', 'because', 'My', 'loneliness', 'is', 'killing', 'me', '(And', 'I)', 'I', 'must', 'confess,', 'I', 'still', 'believe', '(Still', 'believe)', 'When', \"I'm\", 'not', 'with', 'you,', 'I', 'lose', 'my', 'mind', 'Give', 'me', 'a', 'sign', 'Hit', 'me,', 'baby,', 'one', 'more', 'time', 'Oh,', 'baby,', 'baby', 'The', 'reason', 'I', 'breathe', 'is', 'you', '(Oh,', 'yeah)', 'Boy,', 'you', 'got', 'me', 'blinded', 'Oh,', 'pretty,', 'baby', \"There's\", 'nothing', 'that', 'I', \"wouldn't\", 'do', \"It's\", 'not', 'the', 'way', 'I', 'planned', 'it', 'Show', 'me', 'how', 'you', 'want', 'it', 'to', 'be', 'Tell', 'me,', 'baby,', \"'cause\", 'I', 'need', 'to', 'know', 'now', 'Oh,', 'because', 'My', 'loneliness', 'is', 'killing', 'me', '(And', 'I)', 'I', 'must', 'confess,', 'I', 'still', 'believe', '(Still', 'believe)', 'When', \"I'm\", 'not', 'with', 'you,', 'I', 'lose', 'my', 'mind', 'Give', 'me', 'a', 'sign', 'Hit', 'me,', 'baby,', 'one', 'more', 'time', 'You', 'might', 'also', 'like', 'Oh,', 'baby,', 'baby', '(Oh)', 'Oh,', 'baby,', 'baby', '(Yeah)', 'Oh,', 'baby,', 'baby', 'How', 'was', 'I', 'supposed', 'to', 'know?', 'Oh,', 'pretty,', 'baby', 'I', \"shouldn't\", 'have', 'let', 'you', 'go', 'I', 'must', 'confess', 'that', 'my', 'loneliness', 'is', 'killing', 'me', 'now', \"Don't\", 'you', 'know', 'I', 'still', 'believe', 'That', 'you', 'will', 'be', 'here', 'and', 'give', 'me', 'a', 'sign', 'Hit', 'me,', 'baby,', 'one', 'more', 'time', 'My', 'loneliness', 'is', 'killing', 'me', '(And', 'I)', 'I', 'must', 'confess,', 'I', 'still', 'believe', '(Still', 'believe)', 'When', \"I'm\", 'not', 'with', 'you,', 'I', 'lose', 'my', 'mind', 'Give', 'me', 'a', 'sign', 'Hit', 'me,', 'baby,', 'one', 'more', 'time', 'I', 'must', 'confess', '(My', 'loneliness)', 'That', 'my', 'loneliness', '(Is', 'killing', 'me)', 'Is', 'killing', 'me', 'now', '(I', 'must', 'confess,', 'I', 'still', 'believe)', \"Don't\", 'you', 'know', 'I', 'still', 'believe', '(When', \"I'm\", 'not', 'with', 'you)', 'That', 'you', 'will', 'be', 'here', '(I', 'lose', 'my', 'mind)', 'And', 'give', 'me', 'a', 'sign', 'Hit', 'me,', 'baby,', 'one', 'more', 'ti']\n",
      "False\n",
      "['Baby,', \"can't\", 'you', 'see', \"I'm\", 'calling?', 'A', 'guy', 'like', 'you', 'should', 'wear', 'a', 'warning', \"It's\", 'dangerous,', \"I'm\", 'falling', \"There's\", 'no', 'escape,', 'I', \"can't\", 'wait', 'I', 'need', 'a', 'hit,', 'baby,', 'give', 'me', 'it', \"You're\", 'dangerous,', \"I'm\", \"lovin'\", 'it', 'Too', 'high,', \"can't\", 'come', 'down', 'Losing', 'my', 'head,', \"spinnin'\", \"'round\", 'and', \"'round\", 'Do', 'you', 'feel', 'me', 'now?', 'With', 'a', 'taste', 'of', 'your', 'lips,', \"I'm\", 'on', 'a', 'ride', \"You're\", 'toxic,', \"I'm\", \"slippin'\", 'under', 'With', 'a', 'taste', 'of', 'a', 'poison', 'paradise', \"I'm\", 'addicted', 'to', 'you', \"Don't\", 'you', 'know', 'that', \"you're\", 'toxic?', 'And', 'I', 'love', 'what', 'you', 'do', \"Don't\", 'you', 'know', 'that', \"you're\", 'toxic?', \"It's\", 'getting', 'late', 'to', 'give', 'you', 'up', 'I', 'took', 'a', 'sip', 'from', 'my', \"devil's\", 'cup', 'Slowly,', \"it's\", 'taking', 'over', 'me', 'Too', 'high,', \"can't\", 'come', 'down', \"It's\", 'in', 'the', 'air', 'and', \"it's\", 'all', 'around', 'Can', 'you', 'feel', 'me', 'now?', 'With', 'a', 'taste', 'of', 'your', 'lips,', \"I'm\", 'on', 'a', 'ride', \"You're\", 'toxic,', \"I'm\", \"slippin'\", 'under', 'With', 'a', 'taste', 'of', 'a', 'poison', 'paradise', \"I'm\", 'addicted', 'to', 'you', \"Don't\", 'you', 'know', 'that', \"you're\", 'toxic?', 'And', 'I', 'love', 'what', 'you', 'do', \"Don't\", 'you', 'know', 'that', \"you're\", 'toxic?', \"Don't\", 'you', 'know', 'that', \"you're\", 'toxic?', 'You', 'might', 'also', 'like', 'With', 'a', 'taste', 'of', 'your', 'lips,', \"I'm\", 'on', 'a', 'ride', \"You're\", 'toxic,', \"I'm\", \"slippin'\", 'under', 'With', 'a', 'taste', 'of', 'a', 'poison', 'paradise', \"I'm\", 'addicted', 'to', 'you', \"Don't\", 'you', 'know', 'that', \"you're\", 'toxic?', 'With', 'a', 'taste', 'of', 'your', 'lips,', \"I'm\", 'on', 'a', 'ride', \"You're\", 'toxic,', \"I'm\", \"slippin'\", 'under', '(Toxic)', 'With', 'a', 'taste', 'of', 'a', 'poison', 'paradise', \"I'm\", 'addicted', 'to', 'you', \"Don't\", 'you', 'know', 'that', \"you're\", 'toxic?', 'Intoxicate', 'me', 'now', 'with', 'your', \"lovin'\", 'now', 'I', 'think', \"I'm\", 'ready', 'now', '(I', 'think', \"I'm\", 'ready', 'now)', 'Intoxicate', 'me', 'now', 'with', 'your', \"lovin'\", 'now', 'I', 'think', \"I'm\", 'ready', 'no']\n",
      "False\n",
      "['You', 'wanna?', 'You', 'wanna?', 'You', 'want', 'a', 'hot', 'body?', 'You', 'want', 'a', 'Bugatti?', 'You', 'want', 'a', 'Maserati?', 'You', 'better', 'work', 'bitch', 'You', 'want', 'a', 'Lamborghini?', 'Sip', 'martinis?', 'Look', 'hot', 'in', 'a', 'bikini?', 'You', 'better', 'work', 'bitch', 'You', 'wanna', 'live', 'fancy?', 'Live', 'in', 'a', 'big', 'mansion?', 'Party', 'in', 'France?', 'You', 'better', 'work', 'bitch,', 'you', 'better', 'work', 'bitch', 'You', 'better', 'work', 'bitch,', 'you', 'better', 'work', 'bitch', 'Now', 'get', 'to', 'work', 'bitch!', '(Ah-ah)', 'Now', 'get', 'to', 'work', 'bitch!', '(Ah-ah)', 'Bring', 'it', 'on,', 'ring', 'the', 'alarm', \"Don't\", 'stop', 'now,', 'just', 'be', 'the', 'champion', 'Work', 'it', 'hard', 'like', \"it's\", 'your', 'profession', 'Watch', 'out', 'now,', \"'cause\", 'here', 'it', 'comes', 'Here', 'comes', 'the', 'smasher,', 'here', 'comes', 'the', 'master', 'Here', 'comes', 'the', 'big', 'beat,', 'big', 'beat', 'to', 'blast', 'ya', 'No', 'time', 'to', 'quit', 'now,', 'just', 'time', 'to', 'get', 'it', 'now', 'Pick', 'up', 'what', \"I'm\", \"puttin'\", 'down,', 'pick', 'up', 'what', \"I'm\", \"puttin'\", 'down', 'You', 'want', 'a', 'hot', 'body?', 'You', 'want', 'a', 'Bugatti?', 'You', 'want', 'a', 'Maserati?', 'You', 'better', 'work', 'bitch', 'You', 'want', 'a', 'Lamborghini?', 'Sip', 'martinis?', 'Look', 'hot', 'in', 'a', 'bikini?', 'You', 'better', 'work', 'bitch', 'You', 'wanna', 'live', 'fancy?', 'Live', 'in', 'a', 'big', 'mansion?', 'Party', 'in', 'France?', 'You', 'better', 'work', 'bitch,', 'you', 'better', 'work', 'bitch', 'You', 'better', 'work', 'bitch,', 'you', 'better', 'work', 'bitch', 'Now', 'get', 'to', 'work', 'bitch!', '(Ah-ah)', 'Now', 'get', 'to', 'work', 'bitch!', '(Ah-ah)', 'You', 'might', 'also', 'like', 'Break', 'it', 'up,', 'break', 'it', 'down', 'See', 'me', \"comin'\", 'you', 'can', 'hear', 'my', 'sound', 'Tell', 'somebody', 'in', 'your', 'town', 'Spread', 'the', 'word,', 'spread', 'the', 'word', 'Go', 'call', 'the', 'police,', 'go', 'call', 'the', 'governor', 'I', 'bring', 'the', 'treble,', \"don't\", 'mean', 'to', 'trouble', 'ya', 'I', 'make', 'it', 'bubble', 'up,', 'call', 'me', 'the', 'bubbler', 'I', 'am', 'the', 'bad', 'bitch,', 'the', 'bitch', 'that', \"you're\", \"lovin'\", 'up', 'Hold', 'your', 'head', 'high,', 'fingers', 'to', 'the', 'sky', 'They', \"gon'\", 'try', 'and', 'try', 'ya,', 'but', 'they', \"can't\", 'deny', 'ya', 'Keep', 'it', 'moving', 'higher,', 'and', 'higher', 'Keep', 'it', 'moving', 'higher,', 'and', 'higher', 'So', 'hold', 'your', 'head', 'high,', 'fingers', 'to', 'the', 'sky', 'Now', 'they', \"don't\", 'believe', 'ya,', 'but', 'they', 'gonna', 'need', 'ya', 'Keep', 'it', 'moving', 'higher', 'and', 'higher', 'Keep', 'it', 'moving', 'higher', 'and', 'higher', 'and', 'higher', 'Work,', 'work,', 'work,', 'work', 'Work,', 'work,', 'work,', 'work', 'Work,', 'work,', 'work,', 'work', 'Work,', 'work,', 'work,', 'work', 'Work', 'it', 'out,', 'work', 'it', 'out,', 'work', 'it', 'out,', 'work', 'it', 'out', 'Work', 'it', 'out,', 'work', 'it', 'out,', 'work', 'it', 'out,', 'work', 'it', 'out', 'Work', 'it', 'out,', 'work', 'it', 'out,', 'work', 'it', 'out,', 'work', 'it', 'out', 'Work', 'it', 'out,', 'work', 'it', 'out', 'You', 'better', 'work', 'bitch', 'You', 'better', 'work', 'bitc']\n",
      "False\n",
      "['Mmm,', 'yeah', 'Yeah,', 'yeah,', 'yeah,', 'yeah,', 'yeah,', 'yeah', 'Yeah,', 'yeah,', 'yeah,', 'yeah,', 'yeah,', 'yeah', 'I', 'think', 'I', 'did', 'it', 'again', 'I', 'made', 'you', 'believe', \"we're\", 'more', 'than', 'just', 'friends', 'Oh,', 'baby,', 'it', 'might', 'seem', 'like', 'a', 'crush', 'But', 'it', \"doesn't\", 'mean', 'that', \"I'm\", 'serious', \"'Cause\", 'to', 'lose', 'all', 'my', 'senses', 'That', 'is', 'just', 'so', 'typically', 'me', 'Ooh,', 'baby,', 'baby', 'Oops,', 'I', 'did', 'it', 'again', 'I', 'played', 'with', 'your', 'heart', 'Got', 'lost', 'in', 'the', 'game', 'Oh,', 'baby,', 'baby', 'Oops,', 'you', 'think', \"I'm\", 'in', 'love', 'That', \"I'm\", 'sent', 'from', 'above', \"I'm\", 'not', 'that', 'innocent', 'You', 'see,', 'my', 'problem', 'is', 'this', \"I'm\", 'dreaming', 'away', 'Wishing', 'that', 'heroes,', 'they', 'truly', 'exist', 'I', 'cry', 'watching', 'the', 'days', \"Can't\", 'you', 'see', \"I'm\", 'a', 'fool', 'in', 'so', 'many', 'ways?', 'But', 'to', 'lose', 'all', 'my', 'senses', 'That', 'is', 'just', 'so', 'typically', 'me', 'Oh,', 'baby,', 'oh', 'You', 'might', 'also', 'like', 'Oops,', 'I', 'did', 'it', 'again', 'I', 'played', 'with', 'your', 'heart', 'Got', 'lost', 'in', 'the', 'game', 'Oh,', 'baby,', 'baby', 'Oops,', 'you', 'think', \"I'm\", 'in', 'love', 'That', \"I'm\", 'sent', 'from', 'above', \"I'm\", 'not', 'that', 'innocent', 'Yeah,', 'yeah,', 'yeah,', 'yeah,', 'yeah,', 'yeah', 'Yeah,', 'yeah,', 'yeah,', 'yeah,', 'yeah,', 'yeah', '\"All', 'aboard!\"', '\"Britney!', 'Before', 'you', 'go,', \"there's\", 'something', 'I', 'want', 'you', 'to', 'have.\"', '\"Oh,', \"it's\", 'beautiful!', 'But', 'wait', 'a', 'minute,', \"isn't\", 'this...?\"', '\"Yeah,', 'yes,', 'it', 'is.\"', '\"But', 'I', 'thought', 'the', 'old', 'lady', 'dropped', 'it', 'into', 'the', 'ocean', 'in', 'the', 'end.\"', '\"Well,', 'baby,', 'I', 'went', 'down', 'and', 'got', 'it', 'for', 'ya.\"', '\"Aw,', 'you', \"shouldn't\", 'have!\"', 'Oops,', 'I', 'did', 'it', 'again', 'to', 'your', 'heart', 'Got', 'lost', 'in', 'this', 'game,', 'oh,', 'baby', '(Baby)', 'Oops,', 'you', '(Oops,', 'you)', 'Think', 'that', \"I'm\", 'sent', 'from', 'above', \"I'm\", 'not', 'that', 'innocent', 'Oops,', 'I', 'did', 'it', 'again', 'I', 'played', 'with', 'your', 'heart', 'Got', 'lost', 'in', 'the', 'game', '(Yeah,', 'yeah)', 'Oh,', 'baby,', 'baby', 'Oops,', 'you', 'think', \"I'm\", 'in', 'love', 'That', \"I'm\", 'sent', 'from', 'above', '(Yeah', 'yeah)', \"I'm\", 'not', 'that', 'innocent', '(Not', 'that', 'innocent,', 'babe)', 'Oops,', 'I', '(Oops,', 'I)', 'did', 'it', 'again', '(Did', 'it', 'again', 'to', 'your', 'heart)', 'I', 'played', 'with', 'your', 'heart', '(Got', 'lost)', 'Got', 'lost', 'in', 'the', 'game', '(In', 'this', 'game,', 'oh,', 'baby)', 'Oh,', 'baby,', 'baby', 'Oops,', 'you', '(Oops,', 'you)', 'think', \"I'm\", 'in', 'love', '(Think', 'that', \"I'm\", 'sent)', 'That', \"I'm\", 'sent', 'from', 'above', \"I'm\", 'not', 'that', 'innoce']\n",
      "True\n",
      "['La,', 'la,', 'la,', 'la,', 'la-la,', 'la,', 'la', 'La,', 'la,', 'la,', 'la,', 'la-la,', 'la,', 'la', 'La,', 'la,', 'la,', 'la,', 'la-la,', 'la,', 'la', 'La,', 'la,', 'la,', 'la,', 'la-la,', 'la,', 'la', 'Oh,', 'baby,', 'baby,', 'have', 'you', 'seen', 'Amy', 'tonight?', 'Is', 'she', 'in', 'the', 'bathroom,', 'is', 'she', 'smoking', 'up', 'outside?', '(Oh!)', 'Oh,', 'baby,', 'baby,', 'does', 'she', 'take', 'a', 'piece', 'of', 'lime', 'For', 'the', 'drink', 'that', \"I'ma\", 'buy', 'her?', 'Do', 'you', 'know', 'just', 'what', 'she', 'likes?', '(Oh!)', 'Oh-oh,', 'tell', 'me,', 'have', 'you', 'seen', 'her?', \"'Cause\", \"I'm\", 'so,', 'oh,', 'I', \"can't\", 'get', 'her', 'off', 'of', 'my', 'brain', 'I', 'just', 'wanna', 'go', 'to', 'the', 'party', 'she', \"gon'\", 'go', 'Can', 'somebody', 'take', 'me', 'home?', 'Ha-ha-he-he-ha-ha-ho', 'Love', 'me,', 'hate', 'me,', 'say', 'what', 'you', 'want', 'about', 'me', 'But', 'all', 'of', 'the', 'boys', 'and', 'all', 'of', 'the', 'girls', 'are', 'begging', 'to,', 'if', 'you', 'seek', 'Amy', 'Love', 'me,', 'hate', 'me,', 'but', \"can't\", 'you', 'see', 'what', 'I', 'see?', 'All', 'of', 'the', 'boys', 'and', 'all', 'of', 'the', 'girls', 'are', 'begging', 'to,', 'if', 'you', 'seek', 'Amy', '(Love', 'me,', 'hate', 'me)', 'La,', 'la,', 'la,', 'la,', 'la-la,', 'la,', 'la', 'La,', 'la,', 'la,', 'la,', 'la-la,', 'la,', 'la', 'Amy', 'told', 'me', 'that', \"she's\", 'gonna', 'meet', 'me', 'up', 'I', \"don't\", 'know', 'where', 'or', 'when,', 'and', 'now', \"they're\", 'closing', 'up', 'the', 'club', '(Oh!)', \"I've\", 'seen', 'her', 'once', 'or', 'twice', 'before,', 'she', 'knows', 'my', 'face', 'But', \"it's\", 'hard', 'to', 'see', 'with', 'all', 'the', 'people', 'standing', 'in', 'the', 'way', '(Oh!)', 'Oh-oh,', 'tell', 'me,', 'have', 'you', 'seen', 'her?', \"'Cause\", \"I'm\", 'so,', 'oh,', 'I', \"can't\", 'get', 'her', 'off', 'of', 'my', 'brain', 'I', 'just', 'wanna', 'go', 'to', 'the', 'party', 'she', \"gon'\", 'go', 'Can', 'somebody', 'take', 'me', 'home?', 'Ha-ha-he-he-ha-ha-ho', 'You', 'might', 'also', 'like', 'Love', 'me,', 'hate', 'me,', 'say', 'what', 'you', 'want', 'about', 'me', 'But', 'all', 'of', 'the', 'boys', 'and', 'all', 'of', 'the', 'girls', 'are', 'begging', 'to,', 'if', 'you', 'seek', 'Amy', 'Love', 'me,', 'hate', 'me,', 'but', \"can't\", 'you', 'see', 'what', 'I', 'see?', 'All', 'of', 'the', 'boys', 'and', 'all', 'of', 'the', 'girls', 'are', 'begging', 'to,', 'if', 'you', 'seek', 'Amy', '(Love', 'me,', 'hate', 'me)', 'Oh,', 'say', 'what', 'you', 'want', 'about', 'me', 'Oh,', 'but', \"can't\", 'you', 'see', 'what', 'I', 'see?', '(Love', 'me,', 'hate', 'me)', 'Oh,', 'say', 'what', 'you', 'want', 'about', 'me', \"('Bout\", 'me,', \"'bout\", 'me)', 'So', 'tell', 'me', 'if', 'you', 'see', 'her', '(Let', 'me', 'know', 'what', 'she', 'was', 'wearing,', 'and', 'what', 'she', 'was', 'like)', \"'Cause\", \"I've\", 'been', 'waiting', 'here', 'forever', '(Let', 'me', 'know', 'where', 'she', 'was', 'going,', 'I', \"don't\", 'mind)', 'Oh,', 'baby,', 'baby,', 'if', 'you', 'seek', 'Amy', 'tonight', '(Oh!)', 'Oh,', 'baby,', 'baby,', \"we'll\", 'do', 'whatever', 'you', 'like', 'Oh,', 'baby,', 'baby,', 'baby', 'Oh,', 'baby,', 'baby,', 'baby', 'La,', 'la,', 'la,', 'la,', 'la-la,', 'la,', 'la', 'La,', 'la,', 'la,', 'la,', 'la-la,', 'la,', 'la', 'La,', 'la,', 'la,', 'la,', 'la-la,', 'la,', 'la', 'La,', 'la,', 'la,', 'la,', 'la-la,', 'la,', 'la', 'Love', 'me,', 'hate', 'me,', 'say', 'what', 'you', 'want', 'about', 'me', 'But', 'all', 'of', 'the', 'boys', 'and', 'all', 'of', 'the', 'girls', 'are', 'begging', 'to,', 'if', 'you', 'seek', 'Amy', 'Love', 'me,', 'hate', 'me,', 'but', \"can't\", 'you', 'see', 'what', 'I', 'see?', 'All', 'of', 'the', 'boys', 'and', 'all', 'of', 'the', 'girls', 'are', 'begging', 'to,', 'if', 'you', 'seek', 'Amy', 'Love', 'me,', 'hate', 'me,', 'say', 'what', 'you', 'want', 'about', 'me', '(Yeah,', 'yeah)', 'Love', 'me,', 'hate', 'me,', 'but', \"can't\", 'you', 'see', 'what', 'I', 'see?', 'All', 'of', 'the', 'boys', 'and', 'all', 'of', 'the', 'girls', 'are', 'begging', 'to', 'if', 'you', 'seek', 'Amy', '(Love', 'me,', 'hate', 'me)', 'Oh,', 'say', 'what', 'you', 'want', 'about', 'me', 'Oh,', 'but', \"can't\", 'you', 'see', 'what', 'I', 'see?', '(Love', 'me,', 'hate', 'me)', 'Oh,', 'say', 'what', 'you', 'want', 'about', 'me', 'All', 'of', 'the', 'boys', 'and', 'all', 'of', 'the', 'girls', 'are', 'begging', 'to', 'if', 'you', 'seek', 'A']\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "limit = 5\n",
    "for index, row in df.iterrows():\n",
    "    print(row[\"Lyrics\"].split())\n",
    "    print(\".\"in row[\"Lyrics\"])\n",
    "    limit -= 1\n",
    "    if(limit == 0):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 1024\n",
    "lyrics = [l[:min(len(l), MAX_LENGTH)] for l in list(df[\"Lyrics\"])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.tokenize import Tokenizer\n",
    "\n",
    "\n",
    "tok = Tokenizer()\n",
    "\n",
    "# ## training the tokenizer\n",
    "# tok.fit(sentences = lyrics, path = \"Weights/tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## loading the tokenizer\n",
    "tok.load(path = \"Weights/tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 21:58:54.162232: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tokens': [['<s>', 'I', '_am', '_a', '_little', '_te', 'ap', 'ot', '</s>']],\n",
       " 'token_ids': [[0, 432, 51, 57, 778, 2153, 1821, 6834, 87]]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.tokenize(\"I'm a little teapot\", get_token_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am a little teapot']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode([[0, 432, 51, 57, 778, 2153, 1821, 6834, 87]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39903"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tok.index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [['<s>', 'I', '_am', '_a', '_little', '_te', 'ap', 'ot', '</s>']],\n",
       " 'token_ids': [[0, 432, 51, 57, 778, 2153, 1821, 6834, 87]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.tokenize(\"I'm a little teapot\", get_token_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>I am a little teapot</s>']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode([[0, 432, 51, 57, 778, 2153, 1821, 6834, 87]], remove_special_tokens=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training word2vec model with 80285 sentences\n",
      "finished training >> saving to Weights/embeddings_300_w2v.txt\n"
     ]
    }
   ],
   "source": [
    "from preprocessing.embeddings import Embedding\n",
    "\n",
    "embedding_size = 300\n",
    "tokens = tok.tokenize(lyrics, get_token_ids=True)\n",
    "\n",
    "embedder = Embedding()\n",
    "embedder.train(sentences=tokens[\"tokens\"], embeddings_size=embedding_size, path=f\"Weights/embeddings_{embedding_size}_w2v.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_I', 0.7497004270553589),\n",
       " ('_me', 0.7384284138679504),\n",
       " ('_You', 0.7070844769477844),\n",
       " ('_that', 0.6351985931396484),\n",
       " ('_shudder', 0.6319519281387329),\n",
       " ('_we', 0.6306412220001221),\n",
       " ('_legitimately', 0.6248846054077148),\n",
       " ('_know', 0.6207215785980225),\n",
       " ('_not', 0.6197407841682434),\n",
       " ('_reassure', 0.6174041032791138)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.model.most_similar(\"_you\")\n",
    "# embedder.model.get_vector(\"_you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39903"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80285/80285 [00:02<00:00, 34818.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "word_counts = {}\n",
    "for t in tqdm(tokens[\"tokens\"]):\n",
    "    for w in t:\n",
    "        if w not in word_counts:\n",
    "            word_counts[w] = 0\n",
    "        word_counts[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39903"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [['<s>', 'this', '_is', '_christ', 'mas', '</s>']],\n",
       " 'token_ids': [[0, 14092, 40, 16091, 11467, 87]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.tokenize(\"this is christmas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
